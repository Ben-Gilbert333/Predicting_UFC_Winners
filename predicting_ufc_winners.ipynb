{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting UFC Winners"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing everything needed\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import (accuracy_score, precision_score, ConfusionMatrixDisplay, \n",
    "recall_score, confusion_matrix, precision_score, make_scorer)\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import StackingClassifier, GradientBoostingClassifier\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder, PolynomialFeatures\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R_fighter</th>\n",
       "      <th>B_fighter</th>\n",
       "      <th>R_odds</th>\n",
       "      <th>B_odds</th>\n",
       "      <th>R_ev</th>\n",
       "      <th>B_ev</th>\n",
       "      <th>date</th>\n",
       "      <th>location</th>\n",
       "      <th>country</th>\n",
       "      <th>Winner</th>\n",
       "      <th>...</th>\n",
       "      <th>finish_details</th>\n",
       "      <th>finish_round</th>\n",
       "      <th>finish_round_time</th>\n",
       "      <th>total_fight_time_secs</th>\n",
       "      <th>r_dec_odds</th>\n",
       "      <th>b_dec_odds</th>\n",
       "      <th>r_sub_odds</th>\n",
       "      <th>b_sub_odds</th>\n",
       "      <th>r_ko_odds</th>\n",
       "      <th>b_ko_odds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thiago Santos</td>\n",
       "      <td>Johnny Walker</td>\n",
       "      <td>-150.0</td>\n",
       "      <td>130</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>2021-10-02</td>\n",
       "      <td>Las Vegas, Nevada, USA</td>\n",
       "      <td>USA</td>\n",
       "      <td>Red</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5:00</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>800.0</td>\n",
       "      <td>900.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>-110.0</td>\n",
       "      <td>175.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alex Oliveira</td>\n",
       "      <td>Niko Price</td>\n",
       "      <td>170.0</td>\n",
       "      <td>-200</td>\n",
       "      <td>170.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>2021-10-02</td>\n",
       "      <td>Las Vegas, Nevada, USA</td>\n",
       "      <td>USA</td>\n",
       "      <td>Blue</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5:00</td>\n",
       "      <td>900.0</td>\n",
       "      <td>450.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>700.0</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>550.0</td>\n",
       "      <td>120.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Misha Cirkunov</td>\n",
       "      <td>Krzysztof Jotko</td>\n",
       "      <td>110.0</td>\n",
       "      <td>-130</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>76.923077</td>\n",
       "      <td>2021-10-02</td>\n",
       "      <td>Las Vegas, Nevada, USA</td>\n",
       "      <td>USA</td>\n",
       "      <td>Blue</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5:00</td>\n",
       "      <td>900.0</td>\n",
       "      <td>550.0</td>\n",
       "      <td>275.0</td>\n",
       "      <td>275.0</td>\n",
       "      <td>1400.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>185.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alexander Hernandez</td>\n",
       "      <td>Mike Breeden</td>\n",
       "      <td>-675.0</td>\n",
       "      <td>475</td>\n",
       "      <td>14.814815</td>\n",
       "      <td>475.000000</td>\n",
       "      <td>2021-10-02</td>\n",
       "      <td>Las Vegas, Nevada, USA</td>\n",
       "      <td>USA</td>\n",
       "      <td>Red</td>\n",
       "      <td>...</td>\n",
       "      <td>Punch</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1:20</td>\n",
       "      <td>80.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>900.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>3500.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>1100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Joe Solecki</td>\n",
       "      <td>Jared Gordon</td>\n",
       "      <td>-135.0</td>\n",
       "      <td>115</td>\n",
       "      <td>74.074074</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>2021-10-02</td>\n",
       "      <td>Las Vegas, Nevada, USA</td>\n",
       "      <td>USA</td>\n",
       "      <td>Blue</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5:00</td>\n",
       "      <td>900.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>900.0</td>\n",
       "      <td>600.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 119 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             R_fighter        B_fighter  R_odds  B_odds        R_ev  \\\n",
       "0        Thiago Santos    Johnny Walker  -150.0     130   66.666667   \n",
       "1        Alex Oliveira       Niko Price   170.0    -200  170.000000   \n",
       "2       Misha Cirkunov  Krzysztof Jotko   110.0    -130  110.000000   \n",
       "3  Alexander Hernandez     Mike Breeden  -675.0     475   14.814815   \n",
       "4          Joe Solecki     Jared Gordon  -135.0     115   74.074074   \n",
       "\n",
       "         B_ev        date                location country Winner  ...  \\\n",
       "0  130.000000  2021-10-02  Las Vegas, Nevada, USA     USA    Red  ...   \n",
       "1   50.000000  2021-10-02  Las Vegas, Nevada, USA     USA   Blue  ...   \n",
       "2   76.923077  2021-10-02  Las Vegas, Nevada, USA     USA   Blue  ...   \n",
       "3  475.000000  2021-10-02  Las Vegas, Nevada, USA     USA    Red  ...   \n",
       "4  115.000000  2021-10-02  Las Vegas, Nevada, USA     USA   Blue  ...   \n",
       "\n",
       "   finish_details finish_round finish_round_time  total_fight_time_secs  \\\n",
       "0             NaN          5.0              5:00                 1500.0   \n",
       "1             NaN          3.0              5:00                  900.0   \n",
       "2             NaN          3.0              5:00                  900.0   \n",
       "3           Punch          1.0              1:20                   80.0   \n",
       "4             NaN          3.0              5:00                  900.0   \n",
       "\n",
       "   r_dec_odds  b_dec_odds  r_sub_odds  b_sub_odds  r_ko_odds  b_ko_odds  \n",
       "0       800.0       900.0      2000.0      1600.0     -110.0      175.0  \n",
       "1       450.0       350.0       700.0      1100.0      550.0      120.0  \n",
       "2       550.0       275.0       275.0      1400.0      600.0      185.0  \n",
       "3       175.0       900.0       500.0      3500.0      110.0     1100.0  \n",
       "4       165.0       200.0       400.0      1200.0      900.0      600.0  \n",
       "\n",
       "[5 rows x 119 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the data and display a preview\n",
    "df = pd.read_csv('data/ufc-master.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4896 entries, 0 to 4895\n",
      "Data columns (total 119 columns):\n",
      " #   Column                        Dtype  \n",
      "---  ------                        -----  \n",
      " 0   R_fighter                     object \n",
      " 1   B_fighter                     object \n",
      " 2   R_odds                        float64\n",
      " 3   B_odds                        int64  \n",
      " 4   R_ev                          float64\n",
      " 5   B_ev                          float64\n",
      " 6   date                          object \n",
      " 7   location                      object \n",
      " 8   country                       object \n",
      " 9   Winner                        object \n",
      " 10  title_bout                    bool   \n",
      " 11  weight_class                  object \n",
      " 12  gender                        object \n",
      " 13  no_of_rounds                  int64  \n",
      " 14  B_current_lose_streak         int64  \n",
      " 15  B_current_win_streak          int64  \n",
      " 16  B_draw                        int64  \n",
      " 17  B_avg_SIG_STR_landed          float64\n",
      " 18  B_avg_SIG_STR_pct             float64\n",
      " 19  B_avg_SUB_ATT                 float64\n",
      " 20  B_avg_TD_landed               float64\n",
      " 21  B_avg_TD_pct                  float64\n",
      " 22  B_longest_win_streak          int64  \n",
      " 23  B_losses                      int64  \n",
      " 24  B_total_rounds_fought         int64  \n",
      " 25  B_total_title_bouts           int64  \n",
      " 26  B_win_by_Decision_Majority    int64  \n",
      " 27  B_win_by_Decision_Split       int64  \n",
      " 28  B_win_by_Decision_Unanimous   int64  \n",
      " 29  B_win_by_KO/TKO               int64  \n",
      " 30  B_win_by_Submission           int64  \n",
      " 31  B_win_by_TKO_Doctor_Stoppage  int64  \n",
      " 32  B_wins                        int64  \n",
      " 33  B_Stance                      object \n",
      " 34  B_Height_cms                  float64\n",
      " 35  B_Reach_cms                   float64\n",
      " 36  B_Weight_lbs                  int64  \n",
      " 37  R_current_lose_streak         int64  \n",
      " 38  R_current_win_streak          int64  \n",
      " 39  R_draw                        int64  \n",
      " 40  R_avg_SIG_STR_landed          float64\n",
      " 41  R_avg_SIG_STR_pct             float64\n",
      " 42  R_avg_SUB_ATT                 float64\n",
      " 43  R_avg_TD_landed               float64\n",
      " 44  R_avg_TD_pct                  float64\n",
      " 45  R_longest_win_streak          int64  \n",
      " 46  R_losses                      int64  \n",
      " 47  R_total_rounds_fought         int64  \n",
      " 48  R_total_title_bouts           int64  \n",
      " 49  R_win_by_Decision_Majority    int64  \n",
      " 50  R_win_by_Decision_Split       int64  \n",
      " 51  R_win_by_Decision_Unanimous   int64  \n",
      " 52  R_win_by_KO/TKO               int64  \n",
      " 53  R_win_by_Submission           int64  \n",
      " 54  R_win_by_TKO_Doctor_Stoppage  int64  \n",
      " 55  R_wins                        int64  \n",
      " 56  R_Stance                      object \n",
      " 57  R_Height_cms                  float64\n",
      " 58  R_Reach_cms                   float64\n",
      " 59  R_Weight_lbs                  int64  \n",
      " 60  R_age                         int64  \n",
      " 61  B_age                         int64  \n",
      " 62  lose_streak_dif               int64  \n",
      " 63  win_streak_dif                int64  \n",
      " 64  longest_win_streak_dif        int64  \n",
      " 65  win_dif                       int64  \n",
      " 66  loss_dif                      int64  \n",
      " 67  total_round_dif               int64  \n",
      " 68  total_title_bout_dif          int64  \n",
      " 69  ko_dif                        int64  \n",
      " 70  sub_dif                       int64  \n",
      " 71  height_dif                    float64\n",
      " 72  reach_dif                     float64\n",
      " 73  age_dif                       int64  \n",
      " 74  sig_str_dif                   float64\n",
      " 75  avg_sub_att_dif               float64\n",
      " 76  avg_td_dif                    float64\n",
      " 77  empty_arena                   int64  \n",
      " 78  constant_1                    int64  \n",
      " 79  B_match_weightclass_rank      float64\n",
      " 80  R_match_weightclass_rank      float64\n",
      " 81  R_Women's Flyweight_rank      float64\n",
      " 82  R_Women's Featherweight_rank  float64\n",
      " 83  R_Women's Strawweight_rank    float64\n",
      " 84  R_Women's Bantamweight_rank   float64\n",
      " 85  R_Heavyweight_rank            float64\n",
      " 86  R_Light Heavyweight_rank      float64\n",
      " 87  R_Middleweight_rank           float64\n",
      " 88  R_Welterweight_rank           float64\n",
      " 89  R_Lightweight_rank            float64\n",
      " 90  R_Featherweight_rank          float64\n",
      " 91  R_Bantamweight_rank           float64\n",
      " 92  R_Flyweight_rank              float64\n",
      " 93  R_Pound-for-Pound_rank        float64\n",
      " 94  B_Women's Flyweight_rank      float64\n",
      " 95  B_Women's Featherweight_rank  float64\n",
      " 96  B_Women's Strawweight_rank    float64\n",
      " 97  B_Women's Bantamweight_rank   float64\n",
      " 98  B_Heavyweight_rank            float64\n",
      " 99  B_Light Heavyweight_rank      float64\n",
      " 100 B_Middleweight_rank           float64\n",
      " 101 B_Welterweight_rank           float64\n",
      " 102 B_Lightweight_rank            float64\n",
      " 103 B_Featherweight_rank          float64\n",
      " 104 B_Bantamweight_rank           float64\n",
      " 105 B_Flyweight_rank              float64\n",
      " 106 B_Pound-for-Pound_rank        float64\n",
      " 107 better_rank                   object \n",
      " 108 finish                        object \n",
      " 109 finish_details                object \n",
      " 110 finish_round                  float64\n",
      " 111 finish_round_time             object \n",
      " 112 total_fight_time_secs         float64\n",
      " 113 r_dec_odds                    float64\n",
      " 114 b_dec_odds                    float64\n",
      " 115 r_sub_odds                    float64\n",
      " 116 b_sub_odds                    float64\n",
      " 117 r_ko_odds                     float64\n",
      " 118 b_ko_odds                     float64\n",
      "dtypes: bool(1), float64(58), int64(46), object(14)\n",
      "memory usage: 4.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R_odds</th>\n",
       "      <th>B_odds</th>\n",
       "      <th>R_ev</th>\n",
       "      <th>B_ev</th>\n",
       "      <th>no_of_rounds</th>\n",
       "      <th>B_current_lose_streak</th>\n",
       "      <th>B_current_win_streak</th>\n",
       "      <th>B_draw</th>\n",
       "      <th>B_avg_SIG_STR_landed</th>\n",
       "      <th>B_avg_SIG_STR_pct</th>\n",
       "      <th>...</th>\n",
       "      <th>B_Flyweight_rank</th>\n",
       "      <th>B_Pound-for-Pound_rank</th>\n",
       "      <th>finish_round</th>\n",
       "      <th>total_fight_time_secs</th>\n",
       "      <th>r_dec_odds</th>\n",
       "      <th>b_dec_odds</th>\n",
       "      <th>r_sub_odds</th>\n",
       "      <th>b_sub_odds</th>\n",
       "      <th>r_ko_odds</th>\n",
       "      <th>b_ko_odds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4895.000000</td>\n",
       "      <td>4896.000000</td>\n",
       "      <td>4895.000000</td>\n",
       "      <td>4896.000000</td>\n",
       "      <td>4896.000000</td>\n",
       "      <td>4896.000000</td>\n",
       "      <td>4896.000000</td>\n",
       "      <td>4896.000000</td>\n",
       "      <td>3966.000000</td>\n",
       "      <td>4131.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>4274.000000</td>\n",
       "      <td>4274.000000</td>\n",
       "      <td>4093.000000</td>\n",
       "      <td>4077.000000</td>\n",
       "      <td>3847.000000</td>\n",
       "      <td>3835.000000</td>\n",
       "      <td>3847.000000</td>\n",
       "      <td>3834.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-117.640449</td>\n",
       "      <td>66.030637</td>\n",
       "      <td>94.827397</td>\n",
       "      <td>167.083323</td>\n",
       "      <td>3.181985</td>\n",
       "      <td>0.477941</td>\n",
       "      <td>0.875408</td>\n",
       "      <td>0.010621</td>\n",
       "      <td>26.308553</td>\n",
       "      <td>0.444741</td>\n",
       "      <td>...</td>\n",
       "      <td>8.473684</td>\n",
       "      <td>9.485714</td>\n",
       "      <td>2.408049</td>\n",
       "      <td>652.313758</td>\n",
       "      <td>294.064745</td>\n",
       "      <td>416.544027</td>\n",
       "      <td>843.010138</td>\n",
       "      <td>1064.543155</td>\n",
       "      <td>514.231869</td>\n",
       "      <td>647.257173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>268.881452</td>\n",
       "      <td>247.803928</td>\n",
       "      <td>82.843409</td>\n",
       "      <td>136.944643</td>\n",
       "      <td>0.571515</td>\n",
       "      <td>0.769386</td>\n",
       "      <td>1.311379</td>\n",
       "      <td>0.108333</td>\n",
       "      <td>20.935885</td>\n",
       "      <td>0.121332</td>\n",
       "      <td>...</td>\n",
       "      <td>4.259763</td>\n",
       "      <td>4.300283</td>\n",
       "      <td>0.996643</td>\n",
       "      <td>357.911423</td>\n",
       "      <td>230.583958</td>\n",
       "      <td>306.571299</td>\n",
       "      <td>550.126761</td>\n",
       "      <td>627.285034</td>\n",
       "      <td>413.622768</td>\n",
       "      <td>458.846643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1700.000000</td>\n",
       "      <td>-1200.000000</td>\n",
       "      <td>5.882353</td>\n",
       "      <td>8.333333</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>-440.000000</td>\n",
       "      <td>-200.000000</td>\n",
       "      <td>-370.000000</td>\n",
       "      <td>-1250.000000</td>\n",
       "      <td>-550.000000</td>\n",
       "      <td>-275.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-255.000000</td>\n",
       "      <td>-145.000000</td>\n",
       "      <td>39.215686</td>\n",
       "      <td>68.965517</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.610000</td>\n",
       "      <td>0.387500</td>\n",
       "      <td>...</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>297.000000</td>\n",
       "      <td>167.000000</td>\n",
       "      <td>225.000000</td>\n",
       "      <td>435.000000</td>\n",
       "      <td>590.000000</td>\n",
       "      <td>240.000000</td>\n",
       "      <td>325.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-150.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.759615</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>...</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>900.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>349.000000</td>\n",
       "      <td>720.000000</td>\n",
       "      <td>975.000000</td>\n",
       "      <td>435.000000</td>\n",
       "      <td>548.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>126.500000</td>\n",
       "      <td>220.000000</td>\n",
       "      <td>126.500000</td>\n",
       "      <td>220.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>39.075000</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>...</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>13.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>900.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>525.000000</td>\n",
       "      <td>1200.000000</td>\n",
       "      <td>1400.000000</td>\n",
       "      <td>700.000000</td>\n",
       "      <td>880.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>775.000000</td>\n",
       "      <td>1300.000000</td>\n",
       "      <td>775.000000</td>\n",
       "      <td>1300.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>2200.000000</td>\n",
       "      <td>2600.000000</td>\n",
       "      <td>4665.000000</td>\n",
       "      <td>4785.000000</td>\n",
       "      <td>2675.000000</td>\n",
       "      <td>3200.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 104 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            R_odds       B_odds         R_ev         B_ev  no_of_rounds  \\\n",
       "count  4895.000000  4896.000000  4895.000000  4896.000000   4896.000000   \n",
       "mean   -117.640449    66.030637    94.827397   167.083323      3.181985   \n",
       "std     268.881452   247.803928    82.843409   136.944643      0.571515   \n",
       "min   -1700.000000 -1200.000000     5.882353     8.333333      3.000000   \n",
       "25%    -255.000000  -145.000000    39.215686    68.965517      3.000000   \n",
       "50%    -150.000000   130.000000    66.666667   130.000000      3.000000   \n",
       "75%     126.500000   220.000000   126.500000   220.000000      3.000000   \n",
       "max     775.000000  1300.000000   775.000000  1300.000000      5.000000   \n",
       "\n",
       "       B_current_lose_streak  B_current_win_streak       B_draw  \\\n",
       "count            4896.000000           4896.000000  4896.000000   \n",
       "mean                0.477941              0.875408     0.010621   \n",
       "std                 0.769386              1.311379     0.108333   \n",
       "min                 0.000000              0.000000     0.000000   \n",
       "25%                 0.000000              0.000000     0.000000   \n",
       "50%                 0.000000              0.000000     0.000000   \n",
       "75%                 1.000000              1.000000     0.000000   \n",
       "max                 6.000000             12.000000     2.000000   \n",
       "\n",
       "       B_avg_SIG_STR_landed  B_avg_SIG_STR_pct  ...  B_Flyweight_rank  \\\n",
       "count           3966.000000        4131.000000  ...         95.000000   \n",
       "mean              26.308553           0.444741  ...          8.473684   \n",
       "std               20.935885           0.121332  ...          4.259763   \n",
       "min                0.000000           0.000000  ...          1.000000   \n",
       "25%                5.610000           0.387500  ...          5.000000   \n",
       "50%               24.759615           0.450000  ...          8.000000   \n",
       "75%               39.075000           0.510000  ...         12.000000   \n",
       "max              154.000000           1.000000  ...         15.000000   \n",
       "\n",
       "       B_Pound-for-Pound_rank  finish_round  total_fight_time_secs  \\\n",
       "count               35.000000   4274.000000            4274.000000   \n",
       "mean                 9.485714      2.408049             652.313758   \n",
       "std                  4.300283      0.996643             357.911423   \n",
       "min                  2.000000      1.000000               5.000000   \n",
       "25%                  5.000000      1.000000             297.000000   \n",
       "50%                 10.000000      3.000000             900.000000   \n",
       "75%                 13.500000      3.000000             900.000000   \n",
       "max                 15.000000      5.000000            1500.000000   \n",
       "\n",
       "        r_dec_odds   b_dec_odds   r_sub_odds   b_sub_odds    r_ko_odds  \\\n",
       "count  4093.000000  4077.000000  3847.000000  3835.000000  3847.000000   \n",
       "mean    294.064745   416.544027   843.010138  1064.543155   514.231869   \n",
       "std     230.583958   306.571299   550.126761   627.285034   413.622768   \n",
       "min    -440.000000  -200.000000  -370.000000 -1250.000000  -550.000000   \n",
       "25%     167.000000   225.000000   435.000000   590.000000   240.000000   \n",
       "50%     250.000000   349.000000   720.000000   975.000000   435.000000   \n",
       "75%     400.000000   525.000000  1200.000000  1400.000000   700.000000   \n",
       "max    2200.000000  2600.000000  4665.000000  4785.000000  2675.000000   \n",
       "\n",
       "         b_ko_odds  \n",
       "count  3834.000000  \n",
       "mean    647.257173  \n",
       "std     458.846643  \n",
       "min    -275.000000  \n",
       "25%     325.000000  \n",
       "50%     548.500000  \n",
       "75%     880.750000  \n",
       "max    3200.000000  \n",
       "\n",
       "[8 rows x 104 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4896, 119)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to change date column to a datetime object but they are in different formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       2021-10-02\n",
       "1       2021-10-02\n",
       "2       2021-10-02\n",
       "3       2021-10-02\n",
       "4       2021-10-02\n",
       "           ...    \n",
       "4891     3/21/2010\n",
       "4892     3/21/2010\n",
       "4893     3/21/2010\n",
       "4894     3/21/2010\n",
       "4895     3/21/2010\n",
       "Name: date, Length: 4896, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['date']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Needed to make sure all of them were separated by the same sign."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing all / to - in date column\n",
    "df['date'] = df['date'].str.replace('/', '-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first 58 dates were in a different format. They had year-month-day instead of month-day-year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     2021-10-02\n",
       "1     2021-10-02\n",
       "2     2021-10-02\n",
       "3     2021-10-02\n",
       "4     2021-10-02\n",
       "5     2021-10-02\n",
       "6     2021-10-02\n",
       "7     2021-10-02\n",
       "8     2021-10-02\n",
       "9     2021-10-02\n",
       "10    2021-10-02\n",
       "11    2021-09-25\n",
       "12    2021-09-25\n",
       "13    2021-09-25\n",
       "14    2021-09-25\n",
       "15    2021-09-25\n",
       "16    2021-09-25\n",
       "17    2021-09-25\n",
       "18    2021-09-25\n",
       "19    2021-09-25\n",
       "20    2021-09-25\n",
       "21    2021-09-25\n",
       "22    2021-09-25\n",
       "23    2021-09-25\n",
       "24    2021-09-18\n",
       "25    2021-09-18\n",
       "26    2021-09-18\n",
       "27    2021-09-18\n",
       "28    2021-09-18\n",
       "29    2021-09-18\n",
       "30    2021-09-18\n",
       "31    2021-09-18\n",
       "32    2021-09-18\n",
       "33    2021-09-18\n",
       "34    2021-09-18\n",
       "35    2021-09-18\n",
       "36    2021-09-18\n",
       "37    2021-09-04\n",
       "38    2021-09-04\n",
       "39    2021-09-04\n",
       "40    2021-09-04\n",
       "41    2021-09-04\n",
       "42    2021-09-04\n",
       "43    2021-09-04\n",
       "44    2021-09-04\n",
       "45    2021-09-04\n",
       "46    2021-08-28\n",
       "47    2021-08-28\n",
       "48    2021-08-28\n",
       "49    2021-08-28\n",
       "50    2021-08-28\n",
       "51    2021-08-28\n",
       "52    2021-08-28\n",
       "53    2021-08-28\n",
       "54    2021-08-28\n",
       "55    2021-08-28\n",
       "56    2021-08-28\n",
       "57    2021-08-28\n",
       "58     8-21-2021\n",
       "Name: date, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['date'][:59]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wrote a for loop that goes through each row in the `date` column and rearranges the strings by slicing. After this I was able to change the data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only want to change the first 58 values\n",
    "for x in range(58):\n",
    "    # Accessing each value in date column\n",
    "    string = df.loc[x, 'date']\n",
    "    # Slicing to get day, month, and year separated\n",
    "    day = string[8:]\n",
    "    month = string[5:7]\n",
    "    year = string[:4]\n",
    "    # Moving components around to get month-day-year format\n",
    "    new_format = month + '-' + day + '-' + year\n",
    "    # Update the DataFrame\n",
    "    df.loc[x, 'date'] = new_format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changed the data type to a datetime object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting column to datetime from object\n",
    "df['date'] = pd.to_datetime(df['date'], format='%m-%d-%Y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After I changed the data type of the `date` column I decided to explore null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "R_fighter        0\n",
       "B_fighter        0\n",
       "R_odds           1\n",
       "B_odds           0\n",
       "R_ev             1\n",
       "              ... \n",
       "b_dec_odds     819\n",
       "r_sub_odds    1049\n",
       "b_sub_odds    1061\n",
       "r_ko_odds     1049\n",
       "b_ko_odds     1062\n",
       "Length: 119, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking columns with nulls\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of nulls in the columns below because only 10 fighters in each weightclass are ranked at any given moment in time. This means majority of fighters do not have a rank. It is also rare for a nonranked fighter to fight a ranked fighter. I don't think these columns add value so I am comfortable dropping them and getting rid of all those null values they hold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "B_Women's Featherweight_rank    4896\n",
       "R_Women's Featherweight_rank    4889\n",
       "B_Pound-for-Pound_rank          4861\n",
       "B_Women's Flyweight_rank        4852\n",
       "R_Women's Flyweight_rank        4837\n",
       "B_Women's Strawweight_rank      4835\n",
       "B_Women's Bantamweight_rank     4818\n",
       "B_Bantamweight_rank             4811\n",
       "B_Lightweight_rank              4809\n",
       "B_Welterweight_rank             4807\n",
       "B_Featherweight_rank            4806\n",
       "B_Light Heavyweight_rank        4803\n",
       "B_Flyweight_rank                4801\n",
       "B_Middleweight_rank             4794\n",
       "R_Women's Strawweight_rank      4792\n",
       "B_Heavyweight_rank              4786\n",
       "R_Women's Bantamweight_rank     4778\n",
       "R_Featherweight_rank            4763\n",
       "R_Middleweight_rank             4762\n",
       "R_Bantamweight_rank             4759\n",
       "R_Lightweight_rank              4757\n",
       "R_Welterweight_rank             4756\n",
       "R_Light Heavyweight_rank        4755\n",
       "R_Heavyweight_rank              4754\n",
       "R_Flyweight_rank                4754\n",
       "R_Pound-for-Pound_rank          4730\n",
       "B_match_weightclass_rank        4019\n",
       "R_match_weightclass_rank        3568\n",
       "finish_details                  2794\n",
       "b_ko_odds                       1062\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking of list of columns with the most null values\n",
    "nulls = df.isna().sum()\n",
    "nulls.sort_values(ascending=False)[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will also get rid of the column `finish_details` because it has over 1000 nulls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"B_Women's Featherweight_rank\",\n",
       " \"R_Women's Featherweight_rank\",\n",
       " 'B_Pound-for-Pound_rank',\n",
       " \"B_Women's Flyweight_rank\",\n",
       " \"R_Women's Flyweight_rank\",\n",
       " \"B_Women's Strawweight_rank\",\n",
       " \"B_Women's Bantamweight_rank\",\n",
       " 'B_Bantamweight_rank',\n",
       " 'B_Lightweight_rank',\n",
       " 'B_Welterweight_rank',\n",
       " 'B_Featherweight_rank',\n",
       " 'B_Light Heavyweight_rank',\n",
       " 'B_Flyweight_rank',\n",
       " 'B_Middleweight_rank',\n",
       " \"R_Women's Strawweight_rank\",\n",
       " 'B_Heavyweight_rank',\n",
       " \"R_Women's Bantamweight_rank\",\n",
       " 'R_Featherweight_rank',\n",
       " 'R_Middleweight_rank',\n",
       " 'R_Bantamweight_rank',\n",
       " 'R_Lightweight_rank',\n",
       " 'R_Welterweight_rank',\n",
       " 'R_Light Heavyweight_rank',\n",
       " 'R_Heavyweight_rank',\n",
       " 'R_Flyweight_rank',\n",
       " 'R_Pound-for-Pound_rank',\n",
       " 'B_match_weightclass_rank',\n",
       " 'R_match_weightclass_rank',\n",
       " 'finish_details']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating list of all columns to drop\n",
    "columns_to_drop = list(nulls.sort_values(ascending=False)[:29].index)\n",
    "columns_to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the selected columns\n",
    "df.drop(columns_to_drop, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b_ko_odds                      1062\n",
       "b_sub_odds                     1061\n",
       "r_ko_odds                      1049\n",
       "r_sub_odds                     1049\n",
       "B_avg_SIG_STR_landed            930\n",
       "                               ... \n",
       "R_win_by_Decision_Split           0\n",
       "R_win_by_Decision_Unanimous       0\n",
       "R_win_by_KO/TKO                   0\n",
       "R_win_by_Submission               0\n",
       "R_fighter                         0\n",
       "Length: 90, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking of list of columns with the most null values\n",
    "nulls2 = df.isna().sum()\n",
    "nulls2.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I was comfortable dropping the rest of the nulls in the dataset because I still had a lot of data to work with and I thought these columns with the most nulls would be vital features for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2615 entries, 0 to 4286\n",
      "Data columns (total 90 columns):\n",
      " #   Column                        Non-Null Count  Dtype         \n",
      "---  ------                        --------------  -----         \n",
      " 0   R_fighter                     2615 non-null   object        \n",
      " 1   B_fighter                     2615 non-null   object        \n",
      " 2   R_odds                        2615 non-null   float64       \n",
      " 3   B_odds                        2615 non-null   int64         \n",
      " 4   R_ev                          2615 non-null   float64       \n",
      " 5   B_ev                          2615 non-null   float64       \n",
      " 6   date                          2615 non-null   datetime64[ns]\n",
      " 7   location                      2615 non-null   object        \n",
      " 8   country                       2615 non-null   object        \n",
      " 9   Winner                        2615 non-null   object        \n",
      " 10  title_bout                    2615 non-null   bool          \n",
      " 11  weight_class                  2615 non-null   object        \n",
      " 12  gender                        2615 non-null   object        \n",
      " 13  no_of_rounds                  2615 non-null   int64         \n",
      " 14  B_current_lose_streak         2615 non-null   int64         \n",
      " 15  B_current_win_streak          2615 non-null   int64         \n",
      " 16  B_draw                        2615 non-null   int64         \n",
      " 17  B_avg_SIG_STR_landed          2615 non-null   float64       \n",
      " 18  B_avg_SIG_STR_pct             2615 non-null   float64       \n",
      " 19  B_avg_SUB_ATT                 2615 non-null   float64       \n",
      " 20  B_avg_TD_landed               2615 non-null   float64       \n",
      " 21  B_avg_TD_pct                  2615 non-null   float64       \n",
      " 22  B_longest_win_streak          2615 non-null   int64         \n",
      " 23  B_losses                      2615 non-null   int64         \n",
      " 24  B_total_rounds_fought         2615 non-null   int64         \n",
      " 25  B_total_title_bouts           2615 non-null   int64         \n",
      " 26  B_win_by_Decision_Majority    2615 non-null   int64         \n",
      " 27  B_win_by_Decision_Split       2615 non-null   int64         \n",
      " 28  B_win_by_Decision_Unanimous   2615 non-null   int64         \n",
      " 29  B_win_by_KO/TKO               2615 non-null   int64         \n",
      " 30  B_win_by_Submission           2615 non-null   int64         \n",
      " 31  B_win_by_TKO_Doctor_Stoppage  2615 non-null   int64         \n",
      " 32  B_wins                        2615 non-null   int64         \n",
      " 33  B_Stance                      2615 non-null   object        \n",
      " 34  B_Height_cms                  2615 non-null   float64       \n",
      " 35  B_Reach_cms                   2615 non-null   float64       \n",
      " 36  B_Weight_lbs                  2615 non-null   int64         \n",
      " 37  R_current_lose_streak         2615 non-null   int64         \n",
      " 38  R_current_win_streak          2615 non-null   int64         \n",
      " 39  R_draw                        2615 non-null   int64         \n",
      " 40  R_avg_SIG_STR_landed          2615 non-null   float64       \n",
      " 41  R_avg_SIG_STR_pct             2615 non-null   float64       \n",
      " 42  R_avg_SUB_ATT                 2615 non-null   float64       \n",
      " 43  R_avg_TD_landed               2615 non-null   float64       \n",
      " 44  R_avg_TD_pct                  2615 non-null   float64       \n",
      " 45  R_longest_win_streak          2615 non-null   int64         \n",
      " 46  R_losses                      2615 non-null   int64         \n",
      " 47  R_total_rounds_fought         2615 non-null   int64         \n",
      " 48  R_total_title_bouts           2615 non-null   int64         \n",
      " 49  R_win_by_Decision_Majority    2615 non-null   int64         \n",
      " 50  R_win_by_Decision_Split       2615 non-null   int64         \n",
      " 51  R_win_by_Decision_Unanimous   2615 non-null   int64         \n",
      " 52  R_win_by_KO/TKO               2615 non-null   int64         \n",
      " 53  R_win_by_Submission           2615 non-null   int64         \n",
      " 54  R_win_by_TKO_Doctor_Stoppage  2615 non-null   int64         \n",
      " 55  R_wins                        2615 non-null   int64         \n",
      " 56  R_Stance                      2615 non-null   object        \n",
      " 57  R_Height_cms                  2615 non-null   float64       \n",
      " 58  R_Reach_cms                   2615 non-null   float64       \n",
      " 59  R_Weight_lbs                  2615 non-null   int64         \n",
      " 60  R_age                         2615 non-null   int64         \n",
      " 61  B_age                         2615 non-null   int64         \n",
      " 62  lose_streak_dif               2615 non-null   int64         \n",
      " 63  win_streak_dif                2615 non-null   int64         \n",
      " 64  longest_win_streak_dif        2615 non-null   int64         \n",
      " 65  win_dif                       2615 non-null   int64         \n",
      " 66  loss_dif                      2615 non-null   int64         \n",
      " 67  total_round_dif               2615 non-null   int64         \n",
      " 68  total_title_bout_dif          2615 non-null   int64         \n",
      " 69  ko_dif                        2615 non-null   int64         \n",
      " 70  sub_dif                       2615 non-null   int64         \n",
      " 71  height_dif                    2615 non-null   float64       \n",
      " 72  reach_dif                     2615 non-null   float64       \n",
      " 73  age_dif                       2615 non-null   int64         \n",
      " 74  sig_str_dif                   2615 non-null   float64       \n",
      " 75  avg_sub_att_dif               2615 non-null   float64       \n",
      " 76  avg_td_dif                    2615 non-null   float64       \n",
      " 77  empty_arena                   2615 non-null   int64         \n",
      " 78  constant_1                    2615 non-null   int64         \n",
      " 79  better_rank                   2615 non-null   object        \n",
      " 80  finish                        2615 non-null   object        \n",
      " 81  finish_round                  2615 non-null   float64       \n",
      " 82  finish_round_time             2615 non-null   object        \n",
      " 83  total_fight_time_secs         2615 non-null   float64       \n",
      " 84  r_dec_odds                    2615 non-null   float64       \n",
      " 85  b_dec_odds                    2615 non-null   float64       \n",
      " 86  r_sub_odds                    2615 non-null   float64       \n",
      " 87  b_sub_odds                    2615 non-null   float64       \n",
      " 88  r_ko_odds                     2615 non-null   float64       \n",
      " 89  b_ko_odds                     2615 non-null   float64       \n",
      "dtypes: bool(1), datetime64[ns](1), float64(30), int64(46), object(12)\n",
      "memory usage: 1.8+ MB\n"
     ]
    }
   ],
   "source": [
    "# Dropping the rest of the null values\n",
    "clean_df = df.dropna()\n",
    "clean_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I needed to know if the winner of the fight is the underdog or the favorite. The data had this column listed as the 'Red' or 'Blue' fighter. I used the `B_odds` and `R_odds` to discover which fighter the underdog was. Then created two new columns `underdog` and `favored`. These contained the names of the fighters. Then was able to replace 'Red' or 'Blue' in the `Winner` column with either 'underdog' or 'favored'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Red     1513\n",
       "Blue    1102\n",
       "Name: Winner, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df['Winner'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-18-f1a5e82c79dc>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clean_df['underdog'] = clean_df.apply(\n",
      "<ipython-input-18-f1a5e82c79dc>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clean_df['favored'] = clean_df.apply(\n"
     ]
    }
   ],
   "source": [
    "# Creating a column that has the name of the underdog by looking at the odds columns\n",
    "clean_df['underdog'] = clean_df.apply(\n",
    "    lambda row: row['R_fighter'] if row['R_odds'] > row['B_odds'] else row['B_fighter'], axis=1)\n",
    "# Creating a column that has the name of the favored fighter by looking at the odds columns\n",
    "clean_df['favored'] = clean_df.apply(\n",
    "    lambda row: row['R_fighter'] if row['R_odds'] < row['B_odds'] else row['B_fighter'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\42ben\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\core\\indexing.py:1765: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(loc, value)\n"
     ]
    }
   ],
   "source": [
    "# Changing Red winners to either underdog or favored\n",
    "clean_df.loc[(clean_df['Winner'] == 'Red') & (clean_df['R_fighter'] == clean_df['underdog']), 'Winner'] = 'underdog'\n",
    "clean_df.loc[(clean_df['Winner'] == 'Red') & (clean_df['R_fighter'] != clean_df['underdog']), 'Winner'] = 'favored'\n",
    "# Changing Blue winners to either underdog or favored\n",
    "clean_df.loc[(clean_df['Winner'] == 'Blue') & (clean_df['B_fighter'] == clean_df['underdog']), 'Winner'] = 'underdog'\n",
    "clean_df.loc[(clean_df['Winner'] == 'Blue') & (clean_df['B_fighter'] != clean_df['underdog']), 'Winner'] = 'favored'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "favored     0.640918\n",
       "underdog    0.359082\n",
       "Name: Winner, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df['Winner'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because I got rid of a lot of rows due to them containing null values I wanted to see if I created a larger class imbalance than what already existed within the whole dataset. After looking at the full dataset it contains almost the exact same percentage of underdog and favored winners."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "favored     0.652982\n",
       "underdog    0.347018\n",
       "Name: Winner, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dropping any nulls that would affect making the changes made below\n",
    "df['R_odds'].dropna(inplace=True)\n",
    "df['B_odds'].dropna(inplace=True)\n",
    "df['R_fighter'].dropna(inplace=True)\n",
    "df['B_fighter'].dropna(inplace=True)\n",
    "\n",
    "# Creating a column that has the name of the underdog by looking at the odds columns\n",
    "df['underdog'] = df.apply(\n",
    "    lambda row: row['R_fighter'] if row['R_odds'] > row['B_odds'] else row['B_fighter'], axis=1)\n",
    "# Creating a column that has the name of the favored fighter by looking at the odds columns\n",
    "df['favored'] = df.apply(\n",
    "    lambda row: row['R_fighter'] if row['R_odds'] < row['B_odds'] else row['B_fighter'], axis=1)\n",
    "\n",
    "# Changing Red winners to either underdog or favored\n",
    "df.loc[(df['Winner'] == 'Red') & (df['R_fighter'] == df['underdog']), 'Winner'] = 'underdog'\n",
    "df.loc[(df['Winner'] == 'Red') & (df['R_fighter'] != df['underdog']), 'Winner'] = 'favored'\n",
    "# Changing Blue winners to either underdog or favored\n",
    "df.loc[(df['Winner'] == 'Blue') & (df['B_fighter'] == df['underdog']), 'Winner'] = 'underdog'\n",
    "df.loc[(df['Winner'] == 'Blue') & (df['B_fighter'] != df['underdog']), 'Winner'] = 'favored'\n",
    "\n",
    "df['Winner'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running a .corr() in order to see which features are the most correlated with the target column. After inspecting the table these are the features I decided to use for my first models:\n",
    "- `B_odds`\n",
    "- `R_odds`\n",
    "- `B_win_by_Decision_Split`\n",
    "- `B_win_by_Decision_Unanimous`\n",
    "- `win_streak_dif`\n",
    "- `loss_dif`\n",
    "- `reach_dif`\n",
    "- `age_dif`\n",
    "- `r_dec_odds`\n",
    "- `b_dec_odds`\n",
    "- `b_sub_odds`\n",
    "- `r_ko_odds`\n",
    "- `b_ko_odds`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R_odds</th>\n",
       "      <th>B_odds</th>\n",
       "      <th>R_ev</th>\n",
       "      <th>B_ev</th>\n",
       "      <th>Winner</th>\n",
       "      <th>title_bout</th>\n",
       "      <th>no_of_rounds</th>\n",
       "      <th>B_current_lose_streak</th>\n",
       "      <th>B_current_win_streak</th>\n",
       "      <th>B_draw</th>\n",
       "      <th>...</th>\n",
       "      <th>empty_arena</th>\n",
       "      <th>constant_1</th>\n",
       "      <th>finish_round</th>\n",
       "      <th>total_fight_time_secs</th>\n",
       "      <th>r_dec_odds</th>\n",
       "      <th>b_dec_odds</th>\n",
       "      <th>r_sub_odds</th>\n",
       "      <th>b_sub_odds</th>\n",
       "      <th>r_ko_odds</th>\n",
       "      <th>b_ko_odds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>R_odds</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.969696</td>\n",
       "      <td>0.820485</td>\n",
       "      <td>-0.936470</td>\n",
       "      <td>0.137393</td>\n",
       "      <td>-0.193818</td>\n",
       "      <td>-0.157417</td>\n",
       "      <td>-0.027434</td>\n",
       "      <td>0.024014</td>\n",
       "      <td>0.010812</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000842</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.036908</td>\n",
       "      <td>-0.019921</td>\n",
       "      <td>0.356514</td>\n",
       "      <td>-0.675676</td>\n",
       "      <td>0.324984</td>\n",
       "      <td>-0.392236</td>\n",
       "      <td>0.508780</td>\n",
       "      <td>-0.601083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B_odds</th>\n",
       "      <td>-0.969696</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.878323</td>\n",
       "      <td>0.892632</td>\n",
       "      <td>-0.120096</td>\n",
       "      <td>0.174785</td>\n",
       "      <td>0.152741</td>\n",
       "      <td>0.036489</td>\n",
       "      <td>-0.035938</td>\n",
       "      <td>-0.006048</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009896</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.035872</td>\n",
       "      <td>0.020138</td>\n",
       "      <td>-0.395906</td>\n",
       "      <td>0.640760</td>\n",
       "      <td>-0.338724</td>\n",
       "      <td>0.382485</td>\n",
       "      <td>-0.531917</td>\n",
       "      <td>0.586146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_ev</th>\n",
       "      <td>0.820485</td>\n",
       "      <td>-0.878323</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.639952</td>\n",
       "      <td>0.029789</td>\n",
       "      <td>-0.116346</td>\n",
       "      <td>-0.117465</td>\n",
       "      <td>-0.043147</td>\n",
       "      <td>0.046130</td>\n",
       "      <td>-0.008782</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.028255</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.053456</td>\n",
       "      <td>-0.048283</td>\n",
       "      <td>0.463268</td>\n",
       "      <td>-0.466056</td>\n",
       "      <td>0.345334</td>\n",
       "      <td>-0.303920</td>\n",
       "      <td>0.532878</td>\n",
       "      <td>-0.476202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B_ev</th>\n",
       "      <td>-0.936470</td>\n",
       "      <td>0.892632</td>\n",
       "      <td>-0.639952</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.177425</td>\n",
       "      <td>0.214087</td>\n",
       "      <td>0.171286</td>\n",
       "      <td>0.010087</td>\n",
       "      <td>-0.008161</td>\n",
       "      <td>-0.024703</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.039891</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.019696</td>\n",
       "      <td>-0.002098</td>\n",
       "      <td>-0.267131</td>\n",
       "      <td>0.715850</td>\n",
       "      <td>-0.281088</td>\n",
       "      <td>0.397651</td>\n",
       "      <td>-0.445476</td>\n",
       "      <td>0.596425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Winner</th>\n",
       "      <td>0.137393</td>\n",
       "      <td>-0.120096</td>\n",
       "      <td>0.029789</td>\n",
       "      <td>-0.177425</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.033924</td>\n",
       "      <td>0.004655</td>\n",
       "      <td>0.003142</td>\n",
       "      <td>0.008900</td>\n",
       "      <td>0.030676</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.022019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001515</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.034843</td>\n",
       "      <td>-0.098497</td>\n",
       "      <td>-0.004560</td>\n",
       "      <td>-0.057562</td>\n",
       "      <td>0.058426</td>\n",
       "      <td>-0.118841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b_dec_odds</th>\n",
       "      <td>-0.675676</td>\n",
       "      <td>0.640760</td>\n",
       "      <td>-0.466056</td>\n",
       "      <td>0.715850</td>\n",
       "      <td>-0.098497</td>\n",
       "      <td>0.264454</td>\n",
       "      <td>0.307118</td>\n",
       "      <td>-0.013570</td>\n",
       "      <td>0.020783</td>\n",
       "      <td>-0.044774</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.034307</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.016122</td>\n",
       "      <td>-0.055197</td>\n",
       "      <td>0.074246</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.194874</td>\n",
       "      <td>0.300780</td>\n",
       "      <td>-0.483733</td>\n",
       "      <td>0.190382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r_sub_odds</th>\n",
       "      <td>0.324984</td>\n",
       "      <td>-0.338724</td>\n",
       "      <td>0.345334</td>\n",
       "      <td>-0.281088</td>\n",
       "      <td>-0.004560</td>\n",
       "      <td>-0.028571</td>\n",
       "      <td>0.023407</td>\n",
       "      <td>-0.006109</td>\n",
       "      <td>0.055771</td>\n",
       "      <td>0.022911</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017766</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.020821</td>\n",
       "      <td>0.021710</td>\n",
       "      <td>0.141541</td>\n",
       "      <td>-0.194874</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.315952</td>\n",
       "      <td>-0.074263</td>\n",
       "      <td>-0.132230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b_sub_odds</th>\n",
       "      <td>-0.392236</td>\n",
       "      <td>0.382485</td>\n",
       "      <td>-0.303920</td>\n",
       "      <td>0.397651</td>\n",
       "      <td>-0.057562</td>\n",
       "      <td>0.143187</td>\n",
       "      <td>0.154065</td>\n",
       "      <td>-0.002178</td>\n",
       "      <td>0.048102</td>\n",
       "      <td>-0.003676</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022419</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.034464</td>\n",
       "      <td>0.017958</td>\n",
       "      <td>-0.070957</td>\n",
       "      <td>0.300780</td>\n",
       "      <td>-0.315952</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.117192</td>\n",
       "      <td>0.024339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r_ko_odds</th>\n",
       "      <td>0.508780</td>\n",
       "      <td>-0.531917</td>\n",
       "      <td>0.532878</td>\n",
       "      <td>-0.445476</td>\n",
       "      <td>0.058426</td>\n",
       "      <td>-0.149433</td>\n",
       "      <td>-0.227844</td>\n",
       "      <td>-0.032786</td>\n",
       "      <td>-0.004365</td>\n",
       "      <td>0.035661</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.030776</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.018983</td>\n",
       "      <td>0.046386</td>\n",
       "      <td>-0.059935</td>\n",
       "      <td>-0.483733</td>\n",
       "      <td>-0.074263</td>\n",
       "      <td>-0.117192</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.211696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b_ko_odds</th>\n",
       "      <td>-0.601083</td>\n",
       "      <td>0.586146</td>\n",
       "      <td>-0.476202</td>\n",
       "      <td>0.596425</td>\n",
       "      <td>-0.118841</td>\n",
       "      <td>0.032263</td>\n",
       "      <td>-0.061496</td>\n",
       "      <td>0.012071</td>\n",
       "      <td>-0.064497</td>\n",
       "      <td>0.004751</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002946</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.029993</td>\n",
       "      <td>0.036643</td>\n",
       "      <td>-0.420457</td>\n",
       "      <td>0.190382</td>\n",
       "      <td>-0.132230</td>\n",
       "      <td>0.024339</td>\n",
       "      <td>-0.211696</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              R_odds    B_odds      R_ev      B_ev    Winner  title_bout  \\\n",
       "R_odds      1.000000 -0.969696  0.820485 -0.936470  0.137393   -0.193818   \n",
       "B_odds     -0.969696  1.000000 -0.878323  0.892632 -0.120096    0.174785   \n",
       "R_ev        0.820485 -0.878323  1.000000 -0.639952  0.029789   -0.116346   \n",
       "B_ev       -0.936470  0.892632 -0.639952  1.000000 -0.177425    0.214087   \n",
       "Winner      0.137393 -0.120096  0.029789 -0.177425  1.000000   -0.033924   \n",
       "...              ...       ...       ...       ...       ...         ...   \n",
       "b_dec_odds -0.675676  0.640760 -0.466056  0.715850 -0.098497    0.264454   \n",
       "r_sub_odds  0.324984 -0.338724  0.345334 -0.281088 -0.004560   -0.028571   \n",
       "b_sub_odds -0.392236  0.382485 -0.303920  0.397651 -0.057562    0.143187   \n",
       "r_ko_odds   0.508780 -0.531917  0.532878 -0.445476  0.058426   -0.149433   \n",
       "b_ko_odds  -0.601083  0.586146 -0.476202  0.596425 -0.118841    0.032263   \n",
       "\n",
       "            no_of_rounds  B_current_lose_streak  B_current_win_streak  \\\n",
       "R_odds         -0.157417              -0.027434              0.024014   \n",
       "B_odds          0.152741               0.036489             -0.035938   \n",
       "R_ev           -0.117465              -0.043147              0.046130   \n",
       "B_ev            0.171286               0.010087             -0.008161   \n",
       "Winner          0.004655               0.003142              0.008900   \n",
       "...                  ...                    ...                   ...   \n",
       "b_dec_odds      0.307118              -0.013570              0.020783   \n",
       "r_sub_odds      0.023407              -0.006109              0.055771   \n",
       "b_sub_odds      0.154065              -0.002178              0.048102   \n",
       "r_ko_odds      -0.227844              -0.032786             -0.004365   \n",
       "b_ko_odds      -0.061496               0.012071             -0.064497   \n",
       "\n",
       "              B_draw  ...  empty_arena  constant_1  finish_round  \\\n",
       "R_odds      0.010812  ...    -0.000842         NaN     -0.036908   \n",
       "B_odds     -0.006048  ...    -0.009896         NaN      0.035872   \n",
       "R_ev       -0.008782  ...    -0.028255         NaN     -0.053456   \n",
       "B_ev       -0.024703  ...    -0.039891         NaN      0.019696   \n",
       "Winner      0.030676  ...    -0.022019         NaN      0.001515   \n",
       "...              ...  ...          ...         ...           ...   \n",
       "b_dec_odds -0.044774  ...    -0.034307         NaN     -0.016122   \n",
       "r_sub_odds  0.022911  ...     0.017766         NaN      0.020821   \n",
       "b_sub_odds -0.003676  ...     0.022419         NaN      0.034464   \n",
       "r_ko_odds   0.035661  ...    -0.030776         NaN      0.018983   \n",
       "b_ko_odds   0.004751  ...    -0.002946         NaN      0.029993   \n",
       "\n",
       "            total_fight_time_secs  r_dec_odds  b_dec_odds  r_sub_odds  \\\n",
       "R_odds                  -0.019921    0.356514   -0.675676    0.324984   \n",
       "B_odds                   0.020138   -0.395906    0.640760   -0.338724   \n",
       "R_ev                    -0.048283    0.463268   -0.466056    0.345334   \n",
       "B_ev                    -0.002098   -0.267131    0.715850   -0.281088   \n",
       "Winner                   0.000013    0.034843   -0.098497   -0.004560   \n",
       "...                           ...         ...         ...         ...   \n",
       "b_dec_odds              -0.055197    0.074246    1.000000   -0.194874   \n",
       "r_sub_odds               0.021710    0.141541   -0.194874    1.000000   \n",
       "b_sub_odds               0.017958   -0.070957    0.300780   -0.315952   \n",
       "r_ko_odds                0.046386   -0.059935   -0.483733   -0.074263   \n",
       "b_ko_odds                0.036643   -0.420457    0.190382   -0.132230   \n",
       "\n",
       "            b_sub_odds  r_ko_odds  b_ko_odds  \n",
       "R_odds       -0.392236   0.508780  -0.601083  \n",
       "B_odds        0.382485  -0.531917   0.586146  \n",
       "R_ev         -0.303920   0.532878  -0.476202  \n",
       "B_ev          0.397651  -0.445476   0.596425  \n",
       "Winner       -0.057562   0.058426  -0.118841  \n",
       "...                ...        ...        ...  \n",
       "b_dec_odds    0.300780  -0.483733   0.190382  \n",
       "r_sub_odds   -0.315952  -0.074263  -0.132230  \n",
       "b_sub_odds    1.000000  -0.117192   0.024339  \n",
       "r_ko_odds    -0.117192   1.000000  -0.211696  \n",
       "b_ko_odds     0.024339  -0.211696   1.000000  \n",
       "\n",
       "[80 rows x 80 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a copy of clean_df\n",
    "correlation = clean_df.copy()\n",
    "# Changing 'Winner' to numeric data\n",
    "correlation['Winner'] = correlation['Winner'].map({'favored': 0, 'underdog': 1})\n",
    "# Changing Stance columns for each fighter to numeric data\n",
    "correlation['R_Stance'] = correlation['R_Stance'].map({'Orthodox': 0, 'Southpaw': 1, 'Switch': 2})\n",
    "correlation['B_Stance'] = correlation['B_Stance'].map({'Orthodox': 0, 'Southpaw': 1, 'Switch': 2})\n",
    "# Running .corr on table\n",
    "correlation.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I ran .value_counts() on all columns to make sure all data looked valid. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    2294\n",
       "5     320\n",
       "4       1\n",
       "Name: no_of_rounds, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df['no_of_rounds'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropped this row because there is no such thing as a 4 round fight. They are either 3 or 5 rounds long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\42ben\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\core\\frame.py:4163: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    }
   ],
   "source": [
    "# Dropping the row\n",
    "clean_df.drop(clean_df.loc[clean_df['no_of_rounds'] == 4].index, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completed data cleaning and performed a train/test split. All features were numeric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting all wanted features equal to X\n",
    "X = clean_df[['B_odds', 'R_odds', 'B_win_by_Decision_Split', 'B_win_by_Decision_Unanimous',\n",
    "                    'win_streak_dif', 'loss_dif', 'reach_dif', 'age_dif', 'r_dec_odds', 'b_dec_odds',\n",
    "                  'b_sub_odds', 'r_ko_odds', 'b_ko_odds']]\n",
    "# Setting target equal to y\n",
    "y = clean_df['Winner']\n",
    "# Performing the train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=333)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A dummy model would pick the underdog every time and be correct about 36% of the time. This also displays an expected yet slight class imbalance, nothing dramatic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "favored     0.637245\n",
       "underdog    0.362755\n",
       "Name: Winner, dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Model (Random Forest)\n",
    "For my first model created a random forest with all default hyperparameters to see if it would over fit to the training data and score a perfect 1.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
       "                (&#x27;forest&#x27;, RandomForestClassifier(random_state=333))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
       "                (&#x27;forest&#x27;, RandomForestClassifier(random_state=333))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=333)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                ('forest', RandomForestClassifier(random_state=333))])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating steps for a Pipeline\n",
    "forest_steps = [('scaler', StandardScaler()),\n",
    "             ('forest', RandomForestClassifier(random_state=333))]\n",
    "# Creating Pipeline with steps\n",
    "forest_pipe = Pipeline(forest_steps)\n",
    "# Fitting the training data to the Pipeline\n",
    "forest_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It did get a perfect score on the training data which gives me confidence I'm working with data that is capable of creating a sufficient model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 1.0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining the predictions from the Pipeline using the training data\n",
    "y_pred = forest_pipe.predict(X_train)\n",
    "# Evaluating the accuracy score on the training data\n",
    "accuracy_score(y_train, y_pred), precision_score(y_train, y_pred, pos_label='underdog')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cross validation accuracy score is pretty good for a first model with all default hyperparameters. It is about 20% higher than the dummy model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6137755102040816"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating mean of the 5-fold cross_val_score on accuracy\n",
    "cross_val_score(forest_pipe, X_train, y_train, cv=5, scoring='accuracy').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I made a custom scorer for precision to use when cross validating because this is the metric I'm mostly concerned with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a custom scorer for precision\n",
    "precision_scorer = make_scorer(precision_score, pos_label='underdog')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This precision score is also not too bad for the first model at 41%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43526394664077506"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating mean of the 5-fold cross_val_score on precision\n",
    "cross_val_score(forest_pipe, X_train, y_train, cv=5, scoring=precision_scorer).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest 2nd iteration (Using GridSearch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Created a GridSearch to try and improve precision score by tweaking the hyperparameters of the random forest. It is overfit so limiting the max_depth was a priority. There is a slight class imbalance so I tried changing the weights. Criterion and n_estimators were also of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Creating parameters for GridSearch\n",
    "# forest_params = {'forest__n_estimators': [50, 100, 150],\n",
    "#                 'forest__max_depth': [5, 50, 100],\n",
    "#                 'forest__class_weight': ['balanced', None],\n",
    "#                 'forest__criterion': ['gini', 'entropy', 'log_loss']}\n",
    "# # GridSearch with the random forest pipeline, parameters above, 5 fold cross validation, and precision score\n",
    "# forest_grid = GridSearchCV(estimator=forest_pipe, param_grid=forest_params, cv=5, scoring=precision_scorer, n_jobs=3)\n",
    "# # Fitting the GridSearch\n",
    "# forest_grid.fit(X_train, y_train)\n",
    "\n",
    "# # Pickling model\n",
    "# with open('pickles/forest_grid.pkl', 'wb') as f:\n",
    "#      pickle.dump(forest_grid, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pickled this model because it can take long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading in pickled model\n",
    "with open('pickles/forest_grid.pkl', 'rb') as f:\n",
    "    forest_grid = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The GridSearch found n_estimators=150, max_depth=50, default class weights, and criterion='entropy' returned the best precision score. It improved quite dramtically for the first GridSearch. Precision went up by approximately 8%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('forest',\n",
      "                 RandomForestClassifier(criterion='entropy', max_depth=50,\n",
      "                                        n_estimators=150, random_state=333))])\n",
      "0.49200305906061487\n"
     ]
    }
   ],
   "source": [
    "# Displaying the best estimator from the GridSearch and the precision score\n",
    "print(forest_grid.best_estimator_)\n",
    "print(forest_grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model is still very overfit to the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying the precison score on the training data\n",
    "y_pred = forest_grid.best_estimator_.predict(X_train)\n",
    "precision_score(y_train, y_pred, pos_label='underdog')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest 3rd iteration (Using GridSearch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tried to improve results with a new GridSearch based on the results from the previous GridSearch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Creating parameters for GridSearch\n",
    "# forest_params2 = {'forest__n_estimators': [140, 150, 160],\n",
    "#                  'forest__max_depth': [45, 50, 75],\n",
    "#                  'forest__class_weight': [{'favored': 1, 'underdog': 2}, None],\n",
    "#                  'forest__criterion': ['gini', 'entropy', 'log_loss']}\n",
    "# # GridSearch with the random forest pipeline, parameters above, 5 fold cross validation, and precision score\n",
    "# forest_grid2 = GridSearchCV(estimator=forest_pipe, param_grid=forest_params2, cv=5, scoring=precision_scorer, n_jobs=3)\n",
    "# # Fitting the GridSearch\n",
    "# forest_grid2.fit(X_train, y_train)\n",
    "\n",
    "# # Pickling model\n",
    "# with open('pickles/forest_grid2.pkl', 'wb') as f:\n",
    "#      pickle.dump(forest_grid2, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pickled this model because it can take long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading in pickled model\n",
    "with open('pickles/forest_grid2.pkl', 'rb') as f:\n",
    "    forest_grid2 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only difference from this GridSearch was it picked a max_depth of 45 instead of 50 but the results were virtually the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('forest',\n",
      "                 RandomForestClassifier(criterion='entropy', max_depth=45,\n",
      "                                        n_estimators=150, random_state=333))])\n",
      "0.49200305906061487\n"
     ]
    }
   ],
   "source": [
    "# Displaying the best estimator from the GridSearch and the precision score\n",
    "print(forest_grid2.best_estimator_)\n",
    "print(forest_grid2.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is still very overfit and scoring perfectly on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying the precison score on the training data\n",
    "y_pred = forest_grid2.best_estimator_.predict(X_train)\n",
    "precision_score(y_train, y_pred, pos_label='underdog')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest with PCA\n",
    "One way to help with an overfit model is to reduce dimensionality. I decided to do this by adding PCA into a new pipeline for a random forest model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()), (&#x27;pca&#x27;, PCA()),\n",
       "                (&#x27;forest&#x27;, RandomForestClassifier(random_state=333))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()), (&#x27;pca&#x27;, PCA()),\n",
       "                (&#x27;forest&#x27;, RandomForestClassifier(random_state=333))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PCA</label><div class=\"sk-toggleable__content\"><pre>PCA()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=333)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()), ('pca', PCA()),\n",
       "                ('forest', RandomForestClassifier(random_state=333))])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating steps for a Pipeline w/ PCA\n",
    "pca_forest_steps = [('scaler', StandardScaler()),\n",
    "                    ('pca', PCA()),\n",
    "                    ('forest', RandomForestClassifier(random_state=333))]\n",
    "# Creating Pipeline with steps\n",
    "pca_forest_pipe = Pipeline(pca_forest_steps)\n",
    "# Fitting the training data to the Pipeline\n",
    "pca_forest_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I set the GridSearch to search through a wide variety of hyperparameters. This included defualt settings and what worked well for the random forest without PCA plus some other values to see what works best now that PCA is being used. For n_components in PCA I used a very wide range because I didn't know how much I should reduce the complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Creating parameters for GridSearch w/ PCA\n",
    "# forest_params3 = {'pca__n_components': [2, 0.8, 0.9],\n",
    "#                   'forest__n_estimators': [50, 100, 150],\n",
    "#                   'forest__max_depth': [5, 50, 100],\n",
    "#                   'forest__class_weight': ['balanced', None],\n",
    "#                   'forest__criterion': ['gini', 'entropy', 'log_loss']}\n",
    "# # GridSearch with the random forest pipeline, parameters above, 5 fold cross validation, and precision score\n",
    "# forest_grid3 = GridSearchCV(estimator=pca_forest_pipe, param_grid=forest_params3, cv=5, scoring=precision_scorer, n_jobs=3)\n",
    "# # Fitting the GridSearch\n",
    "# forest_grid3.fit(X_train, y_train)\n",
    "\n",
    "# # Pickling model\n",
    "# with open('pickles/forest_grid3.pkl', 'wb') as f:\n",
    "#      pickle.dump(forest_grid3, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pickled this model because it can take long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading in pickled model\n",
    "with open('pickles/forest_grid3.pkl', 'rb') as f:\n",
    "    forest_grid3 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This increased the precision score by about 11%! It now earned a precision score of 60%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('pca', PCA(n_components=2)),\n",
      "                ('forest',\n",
      "                 RandomForestClassifier(criterion='entropy', max_depth=5,\n",
      "                                        random_state=333))])\n",
      "0.6\n"
     ]
    }
   ],
   "source": [
    "# Displaying the best estimator from the GridSearch and the precision score\n",
    "print(forest_grid3.best_estimator_)\n",
    "print(forest_grid3.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model is less overfit than the random forest models without PCA. It is still noticeably overfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying the precison score on the training data\n",
    "y_pred = forest_grid3.best_estimator_.predict(X_train)\n",
    "precision_score(y_train, y_pred, pos_label='underdog')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I looked at the weights associated with all features within the two components in order to retrieve information on feature importance. \n",
    "In the first component the features with the heaviest weights are:\n",
    "\n",
    " - `B_odds`\n",
    " - `R_odds`\n",
    " - `age_dif`\n",
    " - `b_dec_odds`\n",
    " - `r_ko_odds`\n",
    " - `b_ko_odds`\n",
    " \n",
    "In the second component the features with the heaviest weights are:\n",
    "\n",
    " - `B_win_by_Decision_Split`\n",
    " - `B_win_by_Decision_Unanimous`\n",
    " - `loss_dif`\n",
    " - `r_dec_odds`\n",
    " - `b_dec_odds`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.48216837, -0.48244519,  0.08104853,  0.05725292, -0.18076274,\n",
       "        -0.20780097, -0.09251538, -0.22119506, -0.19191591,  0.3501079 ,\n",
       "         0.21471459, -0.29551187,  0.3142195 ],\n",
       "       [-0.06332669,  0.0816488 ,  0.48564759,  0.49429965,  0.08964384,\n",
       "        -0.32059116, -0.09015838, -0.18919759, -0.33355674, -0.39703797,\n",
       "        -0.0648606 ,  0.22205341,  0.1788425 ]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_grid3.best_estimator_.named_steps['pca'].components_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest with PCA 2nd Iteration\n",
    "Updated pipeline with hyperparamers that have consistently been the best. Criterion='entropy' and default class weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()), (&#x27;pca&#x27;, PCA()),\n",
       "                (&#x27;forest&#x27;,\n",
       "                 RandomForestClassifier(criterion=&#x27;entropy&#x27;,\n",
       "                                        random_state=333))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()), (&#x27;pca&#x27;, PCA()),\n",
       "                (&#x27;forest&#x27;,\n",
       "                 RandomForestClassifier(criterion=&#x27;entropy&#x27;,\n",
       "                                        random_state=333))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PCA</label><div class=\"sk-toggleable__content\"><pre>PCA()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, random_state=333)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()), ('pca', PCA()),\n",
       "                ('forest',\n",
       "                 RandomForestClassifier(criterion='entropy',\n",
       "                                        random_state=333))])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating steps for a Pipeline w/ PCA\n",
    "pca_forest_steps = [('scaler', StandardScaler()),\n",
    "                    ('pca', PCA()),\n",
    "                    ('forest', RandomForestClassifier(random_state=333, criterion='entropy'))]\n",
    "# Creating Pipeline with steps\n",
    "pca_forest_pipe = Pipeline(pca_forest_steps)\n",
    "# Fitting the training data to the Pipeline\n",
    "pca_forest_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tried to increase the results with new GridSearch. No longer using GridSearch for criterion or class weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Creating parameters for GridSearch w/ PCA\n",
    "# forest_params4 = {'pca__n_components': [2, 3],\n",
    "#                   'forest__n_estimators': [99, 100, 101],\n",
    "#                   'forest__max_depth': [4, 5, 6]}\n",
    "# # GridSearch with the random forest pipeline, parameters above, 5 fold cross validation, and precision score\n",
    "# forest_grid4 = GridSearchCV(estimator=pca_forest_pipe, param_grid=forest_params4, cv=5, scoring=precision_scorer, n_jobs=3)\n",
    "# # Fitting the GridSearch\n",
    "# forest_grid4.fit(X_train, y_train)\n",
    "\n",
    "# with open('pickles/forest_grid4.pkl', 'wb') as f:\n",
    "#      pickle.dump(forest_grid4, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pickled this model because it can take long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading in pickled model\n",
    "with open('pickles/forest_grid4.pkl', 'rb') as f:\n",
    "    forest_grid4 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This GridSearch returned slightly different hyperparameters but virtually the same cross validation scores. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('pca', PCA(n_components=3)),\n",
      "                ('forest',\n",
      "                 RandomForestClassifier(criterion='entropy', max_depth=4,\n",
      "                                        n_estimators=99, random_state=333))])\n",
      "0.6\n"
     ]
    }
   ],
   "source": [
    "# Displaying the best estimator from the GridSearch and the precision score\n",
    "print(forest_grid4.best_estimator_)\n",
    "print(forest_grid4.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After looking at the precision score on training data it is evidently more overfit than the previous model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying the precison score on the training data\n",
    "y_pred = forest_grid4.best_estimator_.predict(X_train)\n",
    "precision_score(y_train, y_pred, pos_label='underdog')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "I was unable to further improve the random forest model. Next I created a logistic regression model. First, without PCA then with PCA in a new pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
       "                (&#x27;logreg&#x27;, LogisticRegression(random_state=333))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
       "                (&#x27;logreg&#x27;, LogisticRegression(random_state=333))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=333)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                ('logreg', LogisticRegression(random_state=333))])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating steps for Pipeline\n",
    "logreg_steps = [('scaler', StandardScaler()),\n",
    "               ('logreg', LogisticRegression(random_state=333))]\n",
    "# Feeding steps to Pipeline\n",
    "logreg_pipe = Pipeline(logreg_steps)\n",
    "# Fitting training data to the Pipeline\n",
    "logreg_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Something appeared to be wrong here. A precision score of 1.0 with a logistic regression that has all defualt hyperparameters doesn't seem right, even on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6377551020408163, 1.0)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining the predictions from the Pipeline using the training data\n",
    "y_pred = logreg_pipe.predict(X_train)\n",
    "# Evaluating the accuracy and precision score on the training data\n",
    "accuracy_score(y_train, y_pred), precision_score(y_train, y_pred, pos_label='underdog')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Displayed confusion matrix to get a better idea of what is happening here. The model only predicted one underdog to win and it was correct prediction resulting in the 1.0 precision score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x1b473ac8820>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ConfusionMatrixDisplay.from_estimator(logreg_pipe, X_train, y_train, display_labels=['favored', 'underdog'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy score was barely lower on the cross valuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6362244897959183"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating mean of the 5-fold cross_val_score on accuracy\n",
    "cross_val_score(logreg_pipe, X_train, y_train, cv=5, scoring='accuracy').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model almost never predicted an underdog to win and must've predicted incorrectly because the precision score is abysmal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\42ben\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\42ben\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\42ben\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.06666666666666667"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating mean of the 5-fold cross_val_score on precision\n",
    "cross_val_score(logreg_pipe, X_train, y_train, cv=5, scoring=precision_scorer).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression (2nd Iteration)\n",
    "Tried to use a GridSearch to improve the logistic regression. Biggest concern is the class weights and regularization given the model never predicted an underdog to win."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\42ben\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "630 fits failed out of a total of 1080.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "90 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\42ben\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\42ben\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\42ben\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\pipeline.py\", line 420, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\42ben\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\42ben\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1168, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\42ben\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "90 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\42ben\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\42ben\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\42ben\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\pipeline.py\", line 420, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\42ben\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\42ben\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1168, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\42ben\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "90 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\42ben\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\42ben\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\42ben\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\pipeline.py\", line 420, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\42ben\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\42ben\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1168, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\42ben\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cholesky supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "90 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\42ben\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\42ben\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\42ben\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\pipeline.py\", line 420, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\42ben\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\42ben\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1168, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\42ben\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "90 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\42ben\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\42ben\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\42ben\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\pipeline.py\", line 420, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\42ben\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\42ben\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1168, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\42ben\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "90 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\42ben\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\42ben\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\42ben\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\pipeline.py\", line 420, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\42ben\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\42ben\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1178, in fit\n",
      "    raise ValueError(\"l1_ratio must be specified when penalty is elasticnet.\")\n",
      "ValueError: l1_ratio must be specified when penalty is elasticnet.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "90 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\42ben\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\42ben\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\42ben\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\pipeline.py\", line 420, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\42ben\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\42ben\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1168, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\42ben\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cholesky supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\42ben\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the test scores are non-finite: [0.36536611 0.36536611 0.36536611 0.36536611        nan        nan\n",
      " 0.36349722        nan        nan        nan        nan        nan\n",
      " 0.36536611 0.36536611 0.36536611 0.36536611        nan        nan\n",
      " 0.36349722        nan        nan        nan        nan        nan\n",
      " 0.40219319 0.40219319 0.40219319 0.40219319        nan        nan\n",
      " 0.41604184        nan        nan        nan        nan        nan\n",
      " 0.40219319 0.40219319 0.40219319 0.40219319        nan        nan\n",
      " 0.41604184        nan        nan        nan        nan        nan\n",
      " 0.04       0.04       0.04       0.04              nan        nan\n",
      " 0.                nan        nan        nan        nan        nan\n",
      " 0.04       0.04       0.04       0.04              nan        nan\n",
      " 0.                nan        nan        nan        nan        nan\n",
      " 0.36574183 0.36574183 0.36574183 0.36574183        nan        nan\n",
      " 0.36555331        nan        nan        nan        nan        nan\n",
      " 0.36574183 0.36574183 0.36574183 0.36574183        nan        nan\n",
      " 0.36555331        nan        nan        nan        nan        nan\n",
      " 0.40472981 0.40420423 0.40420423 0.40472981        nan        nan\n",
      " 0.40555916        nan        nan        nan        nan        nan\n",
      " 0.40472981 0.40420423 0.40420423 0.40472981        nan        nan\n",
      " 0.40555916        nan        nan        nan        nan        nan\n",
      " 0.06666667 0.06666667 0.06666667 0.06666667        nan        nan\n",
      " 0.06666667        nan        nan        nan        nan        nan\n",
      " 0.06666667 0.06666667 0.06666667 0.06666667        nan        nan\n",
      " 0.06666667        nan        nan        nan        nan        nan\n",
      " 0.36612045 0.36612045 0.36612045 0.36612045        nan        nan\n",
      " 0.36593132        nan        nan        nan        nan        nan\n",
      " 0.36612045 0.36612045 0.36612045 0.36612045        nan        nan\n",
      " 0.36593132        nan        nan        nan        nan        nan\n",
      " 0.40456116 0.40456116 0.40395222 0.40456116        nan        nan\n",
      " 0.4040459         nan        nan        nan        nan        nan\n",
      " 0.40456116 0.40456116 0.40456116 0.40456116        nan        nan\n",
      " 0.4040459         nan        nan        nan        nan        nan\n",
      " 0.06666667 0.06666667 0.06666667 0.06666667        nan        nan\n",
      " 0.06666667        nan        nan        nan        nan        nan\n",
      " 0.06666667 0.06666667 0.06666667 0.06666667        nan        nan\n",
      " 0.06666667        nan        nan        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
       "                                       (&#x27;logreg&#x27;,\n",
       "                                        LogisticRegression(random_state=333))]),\n",
       "             n_jobs=3,\n",
       "             param_grid={&#x27;logreg__C&#x27;: [0.1, 1, 10],\n",
       "                         &#x27;logreg__class_weight&#x27;: [{&#x27;favored&#x27;: 1,\n",
       "                                                   &#x27;underdog&#x27;: 10},\n",
       "                                                  &#x27;balanced&#x27;, None],\n",
       "                         &#x27;logreg__max_iter&#x27;: [100, 250],\n",
       "                         &#x27;logreg__penalty&#x27;: [&#x27;l2&#x27;, &#x27;l1&#x27;, &#x27;elasticnet&#x27;],\n",
       "                         &#x27;logreg__solver&#x27;: [&#x27;lbfgs&#x27;, &#x27;sag&#x27;, &#x27;saga&#x27;,\n",
       "                                            &#x27;newton-cholesky&#x27;]},\n",
       "             scoring=make_scorer(precision_score, pos_label=underdog))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
       "                                       (&#x27;logreg&#x27;,\n",
       "                                        LogisticRegression(random_state=333))]),\n",
       "             n_jobs=3,\n",
       "             param_grid={&#x27;logreg__C&#x27;: [0.1, 1, 10],\n",
       "                         &#x27;logreg__class_weight&#x27;: [{&#x27;favored&#x27;: 1,\n",
       "                                                   &#x27;underdog&#x27;: 10},\n",
       "                                                  &#x27;balanced&#x27;, None],\n",
       "                         &#x27;logreg__max_iter&#x27;: [100, 250],\n",
       "                         &#x27;logreg__penalty&#x27;: [&#x27;l2&#x27;, &#x27;l1&#x27;, &#x27;elasticnet&#x27;],\n",
       "                         &#x27;logreg__solver&#x27;: [&#x27;lbfgs&#x27;, &#x27;sag&#x27;, &#x27;saga&#x27;,\n",
       "                                            &#x27;newton-cholesky&#x27;]},\n",
       "             scoring=make_scorer(precision_score, pos_label=underdog))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
       "                (&#x27;logreg&#x27;, LogisticRegression(random_state=333))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=333)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                                       ('logreg',\n",
       "                                        LogisticRegression(random_state=333))]),\n",
       "             n_jobs=3,\n",
       "             param_grid={'logreg__C': [0.1, 1, 10],\n",
       "                         'logreg__class_weight': [{'favored': 1,\n",
       "                                                   'underdog': 10},\n",
       "                                                  'balanced', None],\n",
       "                         'logreg__max_iter': [100, 250],\n",
       "                         'logreg__penalty': ['l2', 'l1', 'elasticnet'],\n",
       "                         'logreg__solver': ['lbfgs', 'sag', 'saga',\n",
       "                                            'newton-cholesky']},\n",
       "             scoring=make_scorer(precision_score, pos_label=underdog))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating parameters for GridSearch\n",
    "logreg_params = {'logreg__penalty': ['l2', 'l1', 'elasticnet'],\n",
    "                'logreg__C': [0.1, 1, 10],\n",
    "                'logreg__class_weight': [{'favored': 1, 'underdog': 10}, 'balanced', None],\n",
    "                'logreg__solver': ['lbfgs', 'sag', 'saga', 'newton-cholesky'],\n",
    "                'logreg__max_iter': [100, 250]}\n",
    "# Creating GridSearch with params above, cv=5, precision score, and logistic regression pipeline\n",
    "logreg_grid = GridSearchCV(estimator=logreg_pipe, param_grid=logreg_params, cv=5, scoring=precision_scorer, n_jobs=3)\n",
    "# Fitting the GridSearch\n",
    "logreg_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was a massive improvement from only one GridSearch. The cross validation score went from ~7% to ~42%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('logreg',\n",
      "                 LogisticRegression(C=0.1, class_weight='balanced',\n",
      "                                    penalty='l1', random_state=333,\n",
      "                                    solver='saga'))])\n",
      "0.41604184150615814\n"
     ]
    }
   ],
   "source": [
    "# Printing the best estimator and best score\n",
    "print(logreg_grid.best_estimator_)\n",
    "print(logreg_grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model barely overfit, in this regard much better than the random forest models. However it is much more underfit than the random forest models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4267578125"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying the precison score on the training data\n",
    "y_pred = logreg_grid.best_estimator_.predict(X_train)\n",
    "precision_score(y_train, y_pred, pos_label='underdog')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression (3rd Iteration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kept most of the same hyperparameters from the best estimator above. Mostly seeing if more regularization by decreasing C will produce a better model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
       "                                       (&#x27;logreg&#x27;,\n",
       "                                        LogisticRegression(random_state=333))]),\n",
       "             n_jobs=3,\n",
       "             param_grid={&#x27;logreg__C&#x27;: [0.1, 0.01, 0.001],\n",
       "                         &#x27;logreg__class_weight&#x27;: [&#x27;balanced&#x27;, None],\n",
       "                         &#x27;logreg__max_iter&#x27;: [100, 500],\n",
       "                         &#x27;logreg__penalty&#x27;: [&#x27;l1&#x27;],\n",
       "                         &#x27;logreg__solver&#x27;: [&#x27;saga&#x27;]},\n",
       "             scoring=make_scorer(precision_score, pos_label=underdog))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
       "                                       (&#x27;logreg&#x27;,\n",
       "                                        LogisticRegression(random_state=333))]),\n",
       "             n_jobs=3,\n",
       "             param_grid={&#x27;logreg__C&#x27;: [0.1, 0.01, 0.001],\n",
       "                         &#x27;logreg__class_weight&#x27;: [&#x27;balanced&#x27;, None],\n",
       "                         &#x27;logreg__max_iter&#x27;: [100, 500],\n",
       "                         &#x27;logreg__penalty&#x27;: [&#x27;l1&#x27;],\n",
       "                         &#x27;logreg__solver&#x27;: [&#x27;saga&#x27;]},\n",
       "             scoring=make_scorer(precision_score, pos_label=underdog))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
       "                (&#x27;logreg&#x27;, LogisticRegression(random_state=333))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" ><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=333)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                                       ('logreg',\n",
       "                                        LogisticRegression(random_state=333))]),\n",
       "             n_jobs=3,\n",
       "             param_grid={'logreg__C': [0.1, 0.01, 0.001],\n",
       "                         'logreg__class_weight': ['balanced', None],\n",
       "                         'logreg__max_iter': [100, 500],\n",
       "                         'logreg__penalty': ['l1'],\n",
       "                         'logreg__solver': ['saga']},\n",
       "             scoring=make_scorer(precision_score, pos_label=underdog))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating parameters for GridSearch\n",
    "logreg_params2 = {'logreg__penalty': ['l1'],\n",
    "                'logreg__C': [0.1, 0.01, 0.001],\n",
    "                'logreg__class_weight': ['balanced', None],\n",
    "                'logreg__solver': ['saga'],\n",
    "                'logreg__max_iter': [100, 500]}\n",
    "# Creating GridSearch with params above, cv=5, precision score, and logistic regression pipeline\n",
    "logreg_grid2 = GridSearchCV(estimator=logreg_pipe, param_grid=logreg_params2, cv=5, scoring=precision_scorer, n_jobs=3)\n",
    "# Fitting the GridSearch\n",
    "logreg_grid2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best estimator remained the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('logreg',\n",
      "                 LogisticRegression(C=0.1, class_weight='balanced',\n",
      "                                    penalty='l1', random_state=333,\n",
      "                                    solver='saga'))])\n",
      "0.41604184150615814\n"
     ]
    }
   ],
   "source": [
    "# Printing the best estimator and best score\n",
    "print(logreg_grid2.best_estimator_)\n",
    "print(logreg_grid2.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression with Polynomial Features\n",
    "I created a new pipeline that included PolynomialFeatures in the steps. The previous logistic regression models are underfit so I am trying to improve this by adding complexity with polynomials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()), (&#x27;poly&#x27;, PolynomialFeatures()),\n",
       "                (&#x27;logreg&#x27;,\n",
       "                 LogisticRegression(C=0.1, class_weight=&#x27;balanced&#x27;,\n",
       "                                    max_iter=5000, penalty=&#x27;l1&#x27;,\n",
       "                                    random_state=333, solver=&#x27;saga&#x27;))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" ><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()), (&#x27;poly&#x27;, PolynomialFeatures()),\n",
       "                (&#x27;logreg&#x27;,\n",
       "                 LogisticRegression(C=0.1, class_weight=&#x27;balanced&#x27;,\n",
       "                                    max_iter=5000, penalty=&#x27;l1&#x27;,\n",
       "                                    random_state=333, solver=&#x27;saga&#x27;))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-24\" type=\"checkbox\" ><label for=\"sk-estimator-id-24\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-25\" type=\"checkbox\" ><label for=\"sk-estimator-id-25\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PolynomialFeatures</label><div class=\"sk-toggleable__content\"><pre>PolynomialFeatures()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-26\" type=\"checkbox\" ><label for=\"sk-estimator-id-26\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=0.1, class_weight=&#x27;balanced&#x27;, max_iter=5000, penalty=&#x27;l1&#x27;,\n",
       "                   random_state=333, solver=&#x27;saga&#x27;)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()), ('poly', PolynomialFeatures()),\n",
       "                ('logreg',\n",
       "                 LogisticRegression(C=0.1, class_weight='balanced',\n",
       "                                    max_iter=5000, penalty='l1',\n",
       "                                    random_state=333, solver='saga'))])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating steps for Pipeline\n",
    "logreg_steps2 = [('scaler', StandardScaler()),\n",
    "                ('poly', PolynomialFeatures()),\n",
    "               ('logreg', LogisticRegression(random_state=333, penalty='l1', C=0.1, solver='saga',\n",
    "                                            class_weight='balanced', max_iter=5000))]\n",
    "# Feeding steps to Pipeline\n",
    "logreg_pipe2 = Pipeline(logreg_steps2)\n",
    "# Fitting training data to the Pipeline\n",
    "logreg_pipe2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Polynomials can get out of hand quickly so I started with only two options: 2 and 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Creating parameters for GridSearch\n",
    "# logreg_params3 = {'poly__degree': [2, 3]}\n",
    "# # Creating GridSearch with params above, cv=5, precision score, and logistic regression pipeline\n",
    "# logreg_grid3 = GridSearchCV(estimator=logreg_pipe2, param_grid=logreg_params3, cv=5, scoring=precision_scorer, n_jobs=3)\n",
    "# # Fitting the GridSearch\n",
    "# logreg_grid3.fit(X_train, y_train)\n",
    "# # Pickling model\n",
    "# with open('pickles/logreg_grid3.pkl', 'wb') as f:\n",
    "#       pickle.dump(logreg_grid3, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pickled this model because it can take long with the GridSearch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading in pickled model\n",
    "with open('pickles/logreg_grid3.pkl', 'rb') as f:\n",
    "    logreg_grid3 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cross validation score increased ever so slightly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('poly', PolynomialFeatures()),\n",
      "                ('logreg',\n",
      "                 LogisticRegression(C=0.1, class_weight='balanced',\n",
      "                                    max_iter=5000, penalty='l1',\n",
      "                                    random_state=333, solver='saga'))])\n",
      "0.4175616759222973\n"
     ]
    }
   ],
   "source": [
    "# Printing the best estimator and best score\n",
    "print(logreg_grid3.best_estimator_)\n",
    "print(logreg_grid3.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This showed it became a bit more overfit but not much. This is expected when increasing complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44334160463192723"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying the precison score on the training data\n",
    "y_pred = logreg_grid3.best_estimator_.predict(X_train)\n",
    "precision_score(y_train, y_pred, pos_label='underdog')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression with Polynomial Features (2nd Iteration)\n",
    "Wanted to see if increasing the polynomials will help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Creating parameters for GridSearch\n",
    "# logreg_params4 = {'poly__degree': [3, 4]}\n",
    "# # Creating GridSearch with params above, cv=5, precision score, and logistic regression pipeline\n",
    "# logreg_grid4 = GridSearchCV(estimator=logreg_pipe2, param_grid=logreg_params4, cv=5, scoring=precision_scorer, n_jobs=3)\n",
    "# # Fitting the GridSearch\n",
    "# logreg_grid4.fit(X_train, y_train)\n",
    "# # Pickling model\n",
    "# with open('pickles/logreg_grid4.pkl', 'wb') as f:\n",
    "#       pickle.dump(logreg_grid4, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pickled this model because it takes a long time to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading in pickled model\n",
    "with open('pickles/logreg_grid4.pkl', 'rb') as f:\n",
    "    logreg_grid4 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This improved the cross validation precision score by less than 1% and was very computationally expensive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('poly', PolynomialFeatures(degree=4)),\n",
      "                ('logreg',\n",
      "                 LogisticRegression(C=0.1, class_weight='balanced',\n",
      "                                    max_iter=5000, penalty='l1',\n",
      "                                    random_state=333, solver='saga'))])\n",
      "0.42180077030812324\n"
     ]
    }
   ],
   "source": [
    "# Printing the best estimator and best score\n",
    "print(logreg_grid4.best_estimator_)\n",
    "print(logreg_grid4.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected with increased complexity it also became slightly more overfit but, still not much. Because these models are taking a long time to run and improving minimally I'm going to move on to a new model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4606413994169096"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying the precison score on the training data\n",
    "y_pred = logreg_grid4.best_estimator_.predict(X_train)\n",
    "precision_score(y_train, y_pred, pos_label='underdog')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GradientBoostingClassifier\n",
    "Next, I decided to try and build a better model using the GradientBoostingClassifier. First I created a new Pipeline and ran the model with all defualt hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
       "                (&#x27;GradBoost&#x27;, GradientBoostingClassifier(random_state=333))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-27\" type=\"checkbox\" ><label for=\"sk-estimator-id-27\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
       "                (&#x27;GradBoost&#x27;, GradientBoostingClassifier(random_state=333))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-28\" type=\"checkbox\" ><label for=\"sk-estimator-id-28\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-29\" type=\"checkbox\" ><label for=\"sk-estimator-id-29\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(random_state=333)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                ('GradBoost', GradientBoostingClassifier(random_state=333))])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating steps for a Pipeline\n",
    "gradient_boost_steps = [('scaler', StandardScaler()),\n",
    "                        ('GradBoost', GradientBoostingClassifier(random_state=333))]\n",
    "# Feeding steps to Pipeline\n",
    "gradient_boost_pipe = Pipeline(gradient_boost_steps)\n",
    "# Fitting training data to the Pipeline\n",
    "gradient_boost_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was a good score on the training data but most likely overfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7535714285714286, 0.8774834437086093)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining the predictions from the Pipeline using the training data\n",
    "y_pred = gradient_boost_pipe.predict(X_train)\n",
    "# Evaluating the accuracy and precision score on the training data\n",
    "accuracy_score(y_train, y_pred), precision_score(y_train, y_pred, pos_label='underdog')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, the cross validation score is much lower, it is overfit. This is a decent precision score though. I wanted to see if I could improve this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46213569857637654"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating mean of the 5-fold cross_val_score on precision\n",
    "cross_val_score(gradient_boost_pipe, X_train, y_train, cv=5, scoring=precision_scorer).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GradientBoostingClassifier with RandomizedGridSearch (2nd Iteration)\n",
    "I decided to use RandomizedGridSearch to begin because it is much more efficient and there are a lot of hyperparameters I could tweak on a GradientBoostingClassifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-9 {color: black;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
       "                                             (&#x27;GradBoost&#x27;,\n",
       "                                              GradientBoostingClassifier(random_state=333))]),\n",
       "                   n_iter=20, n_jobs=3,\n",
       "                   param_distributions={&#x27;GradBoost__learning_rate&#x27;: [0.001,\n",
       "                                                                     0.01, 0.1,\n",
       "                                                                     1, 10],\n",
       "                                        &#x27;GradBoost__loss&#x27;: [&#x27;log_loss&#x27;,\n",
       "                                                            &#x27;exponential&#x27;],\n",
       "                                        &#x27;GradBoost__max_depth&#x27;: [None, 50, 200],\n",
       "                                        &#x27;GradBoost__min_samples_leaf&#x27;: [2, 4,\n",
       "                                                                        8],\n",
       "                                        &#x27;GradBoost__n_estimators&#x27;: [50, 100,\n",
       "                                                                    150, 200]},\n",
       "                   random_state=333,\n",
       "                   scoring=make_scorer(precision_score, pos_label=underdog))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-30\" type=\"checkbox\" ><label for=\"sk-estimator-id-30\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
       "                                             (&#x27;GradBoost&#x27;,\n",
       "                                              GradientBoostingClassifier(random_state=333))]),\n",
       "                   n_iter=20, n_jobs=3,\n",
       "                   param_distributions={&#x27;GradBoost__learning_rate&#x27;: [0.001,\n",
       "                                                                     0.01, 0.1,\n",
       "                                                                     1, 10],\n",
       "                                        &#x27;GradBoost__loss&#x27;: [&#x27;log_loss&#x27;,\n",
       "                                                            &#x27;exponential&#x27;],\n",
       "                                        &#x27;GradBoost__max_depth&#x27;: [None, 50, 200],\n",
       "                                        &#x27;GradBoost__min_samples_leaf&#x27;: [2, 4,\n",
       "                                                                        8],\n",
       "                                        &#x27;GradBoost__n_estimators&#x27;: [50, 100,\n",
       "                                                                    150, 200]},\n",
       "                   random_state=333,\n",
       "                   scoring=make_scorer(precision_score, pos_label=underdog))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-31\" type=\"checkbox\" ><label for=\"sk-estimator-id-31\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
       "                (&#x27;GradBoost&#x27;, GradientBoostingClassifier(random_state=333))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-32\" type=\"checkbox\" ><label for=\"sk-estimator-id-32\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-33\" type=\"checkbox\" ><label for=\"sk-estimator-id-33\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(random_state=333)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                                             ('GradBoost',\n",
       "                                              GradientBoostingClassifier(random_state=333))]),\n",
       "                   n_iter=20, n_jobs=3,\n",
       "                   param_distributions={'GradBoost__learning_rate': [0.001,\n",
       "                                                                     0.01, 0.1,\n",
       "                                                                     1, 10],\n",
       "                                        'GradBoost__loss': ['log_loss',\n",
       "                                                            'exponential'],\n",
       "                                        'GradBoost__max_depth': [None, 50, 200],\n",
       "                                        'GradBoost__min_samples_leaf': [2, 4,\n",
       "                                                                        8],\n",
       "                                        'GradBoost__n_estimators': [50, 100,\n",
       "                                                                    150, 200]},\n",
       "                   random_state=333,\n",
       "                   scoring=make_scorer(precision_score, pos_label=underdog))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Setting params for RandomizedGridSearch\n",
    "# gradient_boost_params = {'GradBoost__learning_rate': [0.001, 0.01, 0.1, 1, 10],\n",
    "#                         'GradBoost__n_estimators': [50, 100, 150, 200],\n",
    "#                         'GradBoost__min_samples_leaf': [2, 4, 8],\n",
    "#                         'GradBoost__loss': ['log_loss', 'exponential'],\n",
    "#                         'GradBoost__max_depth': [None, 50, 200]}\n",
    "# # Creating the RandomizedGridSearch\n",
    "# gradient_boost_grid = RandomizedSearchCV(gradient_boost_pipe, param_distributions=gradient_boost_params, \n",
    "#                                          scoring=precision_scorer, cv=5, random_state=333, n_iter=20, n_jobs=3)\n",
    "# # Fitting the RandomizedGridSearch\n",
    "# gradient_boost_grid.fit(X_train, y_train)\n",
    "\n",
    "# # Pickling this model\n",
    "# with open('pickles/gradient_boost_grid.pkl', 'wb') as f:\n",
    "#        pickle.dump(gradient_boost_grid, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I pickled this model because it takes a couple minutes to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading in pickled model\n",
    "with open('pickles/gradient_boost_grid.pkl', 'rb') as f:\n",
    "    gradient_boost_grid = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The precision score remained close to the same but is a tiny bit better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('GradBoost',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01,\n",
      "                                            loss='exponential', max_depth=50,\n",
      "                                            min_samples_leaf=8,\n",
      "                                            n_estimators=150,\n",
      "                                            random_state=333))])\n",
      "0.4627798679598586\n"
     ]
    }
   ],
   "source": [
    "# Printing the best estimator and best score\n",
    "print(gradient_boost_grid.best_estimator_)\n",
    "print(gradient_boost_grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the model is even more overfit to the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying the precison score on the training data\n",
    "y_pred = gradient_boost_grid.best_estimator_.predict(X_train)\n",
    "precision_score(y_train, y_pred, pos_label='underdog')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GradientBoostingClassifier with GridSearch (3rd Iteration)\n",
    "After I ran the RandomizedGridSearch I had an idea of where to start so I decided to use a GridSearch instead of a RandomizedGridSearch this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Setting params for GridSearch\n",
    "# gradient_boost_params2 = {'GradBoost__learning_rate': [0.001, 0.01, 0.1],\n",
    "#                         'GradBoost__n_estimators': [125, 150, 175],\n",
    "#                         'GradBoost__min_samples_leaf': [8, 10],\n",
    "#                         'GradBoost__loss': ['log_loss', 'exponential'],\n",
    "#                         'GradBoost__max_depth': [25, 50, 100]}\n",
    "# # Creating the GridSearch\n",
    "# gradient_boost_grid2 = GridSearchCV(gradient_boost_pipe, param_grid=gradient_boost_params2, cv=5, scoring=precision_scorer,\n",
    "#                                    n_jobs=3)\n",
    "# # Fitting the GridSearch\n",
    "# gradient_boost_grid2.fit(X_train, y_train)\n",
    "\n",
    "# # Pickling model\n",
    "# with open('pickles/gradient_boost_grid2.pkl', 'wb') as f:\n",
    "#        pickle.dump(gradient_boost_grid2, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pickled this model because it takes a long time to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading in pickled model\n",
    "with open('pickles/gradient_boost_grid2.pkl', 'rb') as f:\n",
    "    gradient_boost_grid2 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This barely increased the precision score and the hyperparameters remained nearly the same as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('GradBoost',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01,\n",
      "                                            loss='exponential', max_depth=50,\n",
      "                                            min_samples_leaf=8,\n",
      "                                            n_estimators=125,\n",
      "                                            random_state=333))])\n",
      "0.47872318790529905\n"
     ]
    }
   ],
   "source": [
    "print(gradient_boost_grid2.best_estimator_)\n",
    "print(gradient_boost_grid2.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is still a very overfit model too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying the precison score on the training data\n",
    "y_pred = gradient_boost_grid2.best_estimator_.predict(X_train)\n",
    "precision_score(y_train, y_pred, pos_label='underdog')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GradientBoostingClassifier with PolynomialFeatures\n",
    "It didn't seem like the GradientBoostingClassifier was able to make any major improvements. However, the first iteration with all defaults had a decent precision score at 46% and had room to become more overfit. So I decided to add complexity with PolynomialFeatures to try and increase the score even though it will likely become more over fit. First I created a new Pipeline that included PolynomialFeatures in the steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-10 {color: black;}#sk-container-id-10 pre{padding: 0;}#sk-container-id-10 div.sk-toggleable {background-color: white;}#sk-container-id-10 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-10 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-10 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-10 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-10 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-10 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-10 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-10 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-10 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-10 div.sk-item {position: relative;z-index: 1;}#sk-container-id-10 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-10 div.sk-item::before, #sk-container-id-10 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-10 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-10 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-10 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-10 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-10 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-10 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-10 div.sk-label-container {text-align: center;}#sk-container-id-10 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-10 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()), (&#x27;poly&#x27;, PolynomialFeatures()),\n",
       "                (&#x27;GradBoost&#x27;, GradientBoostingClassifier(random_state=333))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-34\" type=\"checkbox\" ><label for=\"sk-estimator-id-34\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()), (&#x27;poly&#x27;, PolynomialFeatures()),\n",
       "                (&#x27;GradBoost&#x27;, GradientBoostingClassifier(random_state=333))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-35\" type=\"checkbox\" ><label for=\"sk-estimator-id-35\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-36\" type=\"checkbox\" ><label for=\"sk-estimator-id-36\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PolynomialFeatures</label><div class=\"sk-toggleable__content\"><pre>PolynomialFeatures()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-37\" type=\"checkbox\" ><label for=\"sk-estimator-id-37\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(random_state=333)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()), ('poly', PolynomialFeatures()),\n",
       "                ('GradBoost', GradientBoostingClassifier(random_state=333))])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating steps for a Pipeline\n",
    "gradient_boost_steps2 = [('scaler', StandardScaler()),\n",
    "                         ('poly', PolynomialFeatures()),\n",
    "                        ('GradBoost', GradientBoostingClassifier(random_state=333))]\n",
    "# Feeding steps to Pipeline\n",
    "gradient_boost_pipe2 = Pipeline(gradient_boost_steps2)\n",
    "# Fitting training data to the Pipeline\n",
    "gradient_boost_pipe2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then made new GridSearch only exploring hyperparameters for PolynomialFeatures and leaving the hyperparameters for the GradientBoostingClassifier as defaults in order to see how adding polynomials changes it compared to just a default GradientBoostingClassifier without polynomials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Setting parameters for GridSearch\n",
    "# gradient_boost_params3 = {'poly__degree': [2, 3],\n",
    "#                          'poly__include_bias': [True, False]}\n",
    "# # Creating GridSearch\n",
    "# gradient_boost_grid3 = GridSearchCV(gradient_boost_pipe2, param_grid=gradient_boost_params3, scoring=precision_scorer,\n",
    "#                                    cv=5, n_jobs=3)\n",
    "# # Fitting the GridSearch\n",
    "# gradient_boost_grid3.fit(X_train, y_train)\n",
    "\n",
    "# # Pickling model\n",
    "# with open('pickles/gradient_boost_grid3.pkl', 'wb') as f:\n",
    "#        pickle.dump(gradient_boost_grid3, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pickled this model because it takes a long time to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading in pickled model\n",
    "with open('pickles/gradient_boost_grid3.pkl', 'rb') as f:\n",
    "    gradient_boost_grid3 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PolynomialFeatures barely improved the precision score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('poly', PolynomialFeatures(degree=3)),\n",
      "                ('GradBoost', GradientBoostingClassifier(random_state=333))])\n",
      "0.4340794015514705\n"
     ]
    }
   ],
   "source": [
    "print(gradient_boost_grid3.best_estimator_)\n",
    "print(gradient_boost_grid3.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The added Polynomials did create a much more overfit model but this was expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9776951672862454"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = gradient_boost_grid3.best_estimator_.predict(X_train)\n",
    "precision_score(y_train, y_pred, pos_label='underdog')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
